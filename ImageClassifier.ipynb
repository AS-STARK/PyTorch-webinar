{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing an Image Classifier \n",
    "\n",
    "* Starting with `torchvision.models`\n",
    "* Retraining pretrained models\n",
    "* Modifying Network Layers\n",
    "* Understanding Effects of Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning\n",
    "\n",
    "An important concept and tool to use once you have some basic idea of constructing neural networks is *transfer learning*.  Many of the things that a particular model learns can be applied to other problems that are somewhat similar in domain.  For example—perhaps the most used example of this—a great deal of image recognion amounts to be able to recognize object borders, general lighting conditions, overall shadingm region identification, and other overall image features.  Even if a model happens to be trained to recognize, e.g. houses versus kittens, much of the same pattern recognition would be helpful in distinguishing trucks from elephants.  Especially since training complex models can be extremely slow, and also simply because other people have done a great deal of work in finding good tagged image collections, it would be nice to re-use much of that work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit\n",
    "\n",
    "As with several of the other lessons, I utilize and graciously thank other authors who have provided wondeful examples.  In this case, I found a blog post and code by Gilbert Adjei titled [Transfer Learning with PyTorch](https://heartbeat.fritz.ai/transfer-learning-with-pytorch-cfcb69016c72).  Looking through a fairly large number of similar writeups, I found his the most accessible and manageable of these.  I make some small modifications, but the credit for the code goes primarily to Adjei.\n",
    "\n",
    "What Adjei looks at is using the pretrained `densenet121` model that is one of numerous image models included with PyTorch, and adapting it to identify images of cells that either are or are not parasitized by malaria.  A nice overview of densenet design is contained in the post [The Efficiency of Densenet](https://medium.com/@smallfishbigsea/densenet-2b0889854a92), by Hao Gao.  For this purpose, and of the image models in PyTorch would be similar to work with.  As an exercise, it would be good to try to apply the techniques in this lesson to other provided models, such as AlexNet, VGG, ResNet, SqueezeNet, Inception v3, GoogLeNet (most of those themselves come in a number of variations with differing depths and other design distinctions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: file: not found\r\n"
     ]
    }
   ],
   "source": [
    "!file sample.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file 'sample.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e3621498bb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/Parasitized/C33P1thinF_IMG_20150619_114756a_cell_179.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sample.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2655\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2657\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file 'sample.png'"
     ]
    }
   ],
   "source": [
    "fname = 'data/Parasitized/C33P1thinF_IMG_20150619_114756a_cell_179.png'\n",
    "fname = 'img/cell_images/C'\n",
    "image = Image.open(fname)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "    \n",
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "\n",
    "We have looked at quite a few capabilities in PyTorch and associated tools.  The next step is to go out and use these lovely tools in your own projects.  I'd love to hear back on what you find and see what you create.  Contact me via the repository for this training material (file issues, email me, propose PRs, whatever).\n",
    "\n",
    "Thanks. David Mertz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
