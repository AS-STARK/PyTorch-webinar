{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing with AllenNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\"><b><u>What is AllenNLP?</u></b></font>\n",
    "<a href=\"AllenNLP_0.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">What is SpaCy?</font>\n",
    "<a href=\"AllenNLP_1.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">High Level Interfaces to NLP using PyTorch</font>\n",
    "<a href=\"AllenNLP_2.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">Sentiment Analysis</font>\n",
    "<a href=\"AllenNLP_3.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">TBD</font> \n",
    "<a href=\"AllenNLP_4.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">TBD</font>\n",
    "<a href=\"AllenNLP_5.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>\n",
    "\n",
    "<font size=\"+1\">TBD</font>\n",
    "<a href=\"AllenNLP_6.ipynb\"><img src=\"img/open-notebook.png\" align=\"right\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllenNLP is a library built on top of PyTorch that provides a large number of well tested, powerful, higher-level abstractions that are specifically useful for performing Natural Language Processing tasks with using neural networks.\n",
    "\n",
    "It is much easier to develop and test these NLP models using these higher abstractions than with the lower-level PyTorch basics—even those in `torch.nn` and `torch.nn.functional`.  A lot of the \"busy work with training schedules, metrics, optimization functions, data readers, and other aspects are wrapped in convenience functions or classes within AllenNLP.  However, using AllenNLP, you often make direct use of PyTorch functions, and under the hood all the computational work remains PyTorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllenNLP can be used to construct models in areas such as the following, each of which have [excellent demos](https://allennlp.org/models) at their website.  If you wish to use it so, the tools in AllenNLP are exposed as command line tools as well.  Behavior of models can be configured with JSON files in many cases rather than programmed in Python, giving (optionally) a more declarative format.  Actually, the configurations use a JSON superset called [Jsonnet](https://jsonnet.org/learning/tutorial.html) that can optionally use a few additional constructs such as local variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Comprehension\n",
    "\n",
    "In Python, using a pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46175392/46175392 [00:05<00:00, 7810723.56B/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passage_question_attention\n",
      "span_start_logits\n",
      "span_start_probs\n",
      "span_end_logits\n",
      "span_end_probs\n",
      "best_span\n",
      "best_span_str\n",
      "question_tokens\n",
      "passage_tokens\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/\"\n",
    "                                \"bidaf-model-2017.09.15-charpad.tar.gz\")\n",
    "resp = predictor.predict(\n",
    "  passage=\"The Matrix is a 1999 science fiction action film written and directed by \"\n",
    "          \"The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, \"\n",
    "          \"Hugo Weaving, and Joe Pantoliano.\",\n",
    "  question=\"Who stars in The Matrix?\"\n",
    ")\n",
    "\n",
    "print(\"\\n\".join(resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp['best_span_str']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TEXT='{\"passage\": \"The Matrix is a 1999 science fiction action film written and directed by \n",
    "The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, \n",
    "and Joe Pantoliano.\", \n",
    "\"question\": \"Who stars in The Matrix?\"}' \n",
    "URL_BASE='https://s3-us-west-2.amazonaws.com/allennlp/models'\n",
    "MODEL_URL=$URL_BASE'/bidaf-model-2017.09.15-charpad.tar.gz'\n",
    "RESP=$(echo $TEXT | allennlp predict $MODEL_URL - 2>/dev/null)\n",
    "echo $RESP | sed 's/.*prediction: //' | jq .best_span_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual Entailment\n",
    "\n",
    "We skip the `bash` versions for the rest of these examples.  They can be found at the AllenNLP demo web page linked above.  The [live demo](http://demo.allennlp.org/textual-entailment) visualizes results in a nice way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 697657697/697657697 [01:03<00:00, 11046940.98B/s]\n",
      "WARNING:allennlp.nn.initializers:Did not use initialization regex that was passed: .*token_embedder_tokens\\._projection.*weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecomposableAttentionPredictor\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/\"\n",
    "                                \"decomposable-attention-elmo-2018.02.19.tar.gz\")\n",
    "\n",
    "follows = partial(predictor.predict, \n",
    "                  premise=\"Two women are sitting on a blanket near some \"\n",
    "                          \"rocks talking about politics.\")\n",
    "\n",
    "print(predictor.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_logits\n",
      "label_probs\n",
      "h2p_attention\n",
      "p2h_attention\n",
      "premise_tokens\n",
      "hypothesis_tokens\n"
     ]
    }
   ],
   "source": [
    "resp = follows(hypothesis=\"The pair of women have political talks.\")\n",
    "\n",
    "print(\"\\n\".join(resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   entailment: 63.50%\n",
      "contradiction:  0.38%\n",
      "      neutral: 36.12%\n"
     ]
    }
   ],
   "source": [
    "# The listed target descriptions are built into the DecomposableAttentionPredictor\n",
    "for entailment, prob in zip(\n",
    "    ['entailment', 'contradiction', 'neutral'], resp['label_probs']):\n",
    "    print(f\"{entailment:>13}: {prob*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   entailment:  0.00%\n",
      "contradiction: 99.95%\n",
      "      neutral:  0.05%\n"
     ]
    }
   ],
   "source": [
    "resp = follows(hypothesis=\"Two women are wandering along the shore drinking iced tea.\")\n",
    "\n",
    "for entailment, prob in zip(\n",
    "    ['entailment', 'contradiction', 'neutral'], resp['label_probs']):\n",
    "    print(f\"{entailment:>13}: {prob*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Role Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730942854/730942854 [01:02<00:00, 11784953.35B/s]\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/\"\n",
    "                                \"srl-model-2018.05.25.tar.gz\")\n",
    "resp = predictor.predict(\n",
    "  sentence=\"Did Uriah honestly think he could beat the game in under three hours?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DID \n",
      "  [V: Did] Uriah honestly think he could beat the game in under three hours ? \n",
      "\n",
      "THINK \n",
      "  Did [ARG0: Uriah] [ARGM-MNR: honestly] [V: think] [ARG1: he could beat the game in under three hours] ? \n",
      "\n",
      "COULD \n",
      "  Did Uriah honestly think he [V: could] beat the game in under three hours ? \n",
      "\n",
      "BEAT \n",
      "  Did Uriah honestly think [ARG0: he] [ARGM-MOD: could] [V: beat] [ARG1: the game] [ARGM-TMP: in under three hours] ? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for verb in resp['verbs']:\n",
    "    print(verb['verb'].upper(), '\\n ', verb['description'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 711306412/711306412 [02:38<00:00, 4480962.91B/s] \n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/\"\n",
    "                                \"ner-model-2018.12.18.tar.gz\")\n",
    "resp = predictor.predict(\n",
    "  sentence=\"AllenNLP is a PyTorch-based natural language processing library developed \"\n",
    "           \"at the Allen Institute for Artificial Intelligence in Seattle.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG AllenNLP\n",
      "    is\n",
      "    a\n",
      "ORG PyTorch\n",
      "    -\n",
      "    based\n",
      "    natural\n",
      "    language\n",
      "    processing\n",
      "    library\n",
      "    developed\n",
      "    at\n",
      "    the\n",
      "ORG Allen Institute for Artificial Intelligence\n",
      "    in\n",
      "LOC Seattle\n",
      "    .\n"
     ]
    }
   ],
   "source": [
    "phrase = []\n",
    "for tag, word in zip(resp['tags'], resp['words']):\n",
    "    if tag.startswith('U-'):\n",
    "        print(tag.replace('U-', ''), word)\n",
    "    elif tag == 'O':\n",
    "        print('   ', word)\n",
    "    elif tag.startswith('B-'):\n",
    "        phrase.append(word)\n",
    "    elif tag.startswith('I-'):\n",
    "        phrase.append(word)\n",
    "    elif tag.startswith('L-'):\n",
    "        phrase.append(word)\n",
    "        print(tag.replace('L-', ''), ' '.join(phrase))\n",
    "        phrase = []\n",
    "    else:\n",
    "        print(\"PROBLEM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other demos\n",
    "\n",
    "There are several additional interesing demos provided with the [AllenNLP model examples](https://allennlp.org/models).  Most likely more will be added over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup large cached models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ~/.allennlp/cache/*\n",
    "!rm -rf /tmp/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "\n",
    "**Enhancing an Image Classifier**: Libraries built on top of PyTorch offer very powerful tools for natural language processing.  Next we will return to image classification, and build on pretrained models as a demonstration of re-use neural networks.\n",
    "\n",
    "<a href=\"ImageClassifier.ipynb\"><img src=\"img/open-notebook.png\" align=\"left\"/></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
