{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks with Networks\n",
    "\n",
    "* An image classifier\n",
    "* A regression prediction\n",
    "* Clustering with NNs (note: https://github.com/MarcTLaw/DeepSpectralClusteringToy)\n",
    "* Generative Adversarial Networks (GAN)\n",
    "* Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "\n",
    "**Intermediate Machine Learning with PyTorch**: This last lesson of the Beginning material covered several real world neural networks.  For a deeper dive into some specialize areas, come back for a future webinar session on Intermidiate material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bra_size_chest</th>\n",
       "      <th>bra_size_cup</th>\n",
       "      <th>height</th>\n",
       "      <th>shoe_size</th>\n",
       "      <th>weight</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  bra_size_chest  bra_size_cup  height  shoe_size  weight   TARGET\n",
       "0  30.0            34.0           5.0    62.0        7.0   128.0  6 SHORT\n",
       "1  20.0            34.0           3.0    64.0        8.0   145.0  6 SHORT\n",
       "2  26.0            32.0           4.0    64.0        8.0   148.0  6 SHORT\n",
       "3  43.0            34.0           5.0    61.0        7.0   145.0  6 SHORT\n",
       "4  63.0            38.0           3.0    63.0        8.0   130.0  6 SHORT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/garments.csv.gz')\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age', 'bra_size_chest', 'bra_size_cup', 'height', 'shoe_size', 'weight']]\n",
    "df_one_hot = pd.get_dummies(df)\n",
    "Y = df_one_hot[[col for col in df_one_hot.columns if col.startswith('TARGET')]]\n",
    "labels = [col.replace('TARGET_', '') for col in Y.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of input features\n",
    "in_dim = X.shape[1]\n",
    "\n",
    "# The number of \"polynomial features\" of order 2\n",
    "hidden1 = int(in_dim * 2 + (in_dim * (in_dim-1) / 2) + 1)\n",
    "out_dim = Y.shape[1]\n",
    "\n",
    "# The sizes of the \"inference layers\"/\n",
    "hidden2 = hidden3 = 2 * out_dim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 28, 66, 66, 33)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dim, hidden1, hidden2, hidden3, out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(model, X_train, Y_train, optimizer, batch_size=1000, show_every=250):\n",
    "    for t in range(5000):\n",
    "        # Sample a few training rows\n",
    "        indices = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        X = X_train[indices]\n",
    "        Y = Y_train[indices]\n",
    "        \n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        Y_pred = model(X)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(Y_pred, Y)\n",
    "        if not t % show_every:\n",
    "            print(t, loss)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential NN\n",
    "model = torch.nn.Sequential(\n",
    "    # This layer allows \"polynomial features\"\n",
    "    torch.nn.Linear(in_dim, hidden1),\n",
    "    # The activation is treated as a separate layer\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    # This layer is \"inference\"\n",
    "    torch.nn.Linear(hidden1, hidden2),\n",
    "    # Often Leaky ReLU eliminates the \"dead neuron\" danger\n",
    "    torch.nn.LeakyReLU(), \n",
    "    \n",
    "    # A Dropout layer sometimes reduces co-adaptation of neurons\n",
    "    torch.nn.Dropout(p=0.1),\n",
    "\n",
    "    # This layer is \"inference\"\n",
    "    torch.nn.Linear(hidden2, hidden3),\n",
    "    torch.nn.LeakyReLU(), \n",
    "\n",
    "    # A sigmoid activation is used for a binary decision\n",
    "    # Since we use one-hot encoding, we essentially make a \n",
    "    torch.nn.Linear(hidden3, out_dim),  \n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "# Convert arrays to tensors\n",
    "X_train = torch.from_numpy(X_train.values).float()\n",
    "X_test  = torch.from_numpy(X_test.values).float()\n",
    "Y_train = torch.from_numpy(Y_train.values)[:, np.newaxis].float()\n",
    "Y_test  = torch.from_numpy(Y_test.values)[:, np.newaxis].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3172, grad_fn=<MseLossBackward>)\n",
      "250 tensor(0.1912, grad_fn=<MseLossBackward>)\n",
      "500 tensor(0.1092, grad_fn=<MseLossBackward>)\n",
      "750 tensor(0.0561, grad_fn=<MseLossBackward>)\n",
      "1000 tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "1250 tensor(0.0340, grad_fn=<MseLossBackward>)\n",
      "1500 tensor(0.0320, grad_fn=<MseLossBackward>)\n",
      "1750 tensor(0.0306, grad_fn=<MseLossBackward>)\n",
      "2000 tensor(0.0303, grad_fn=<MseLossBackward>)\n",
      "2250 tensor(0.0300, grad_fn=<MseLossBackward>)\n",
      "2500 tensor(0.0298, grad_fn=<MseLossBackward>)\n",
      "2750 tensor(0.0296, grad_fn=<MseLossBackward>)\n",
      "3000 tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "3250 tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "3500 tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "3750 tensor(0.0293, grad_fn=<MseLossBackward>)\n",
      "4000 tensor(0.0293, grad_fn=<MseLossBackward>)\n",
      "4250 tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "4500 tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "4750 tensor(0.0289, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "## Now run model\n",
    "learning_rate = 1e-5\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "do_training(model, X_train, Y_train, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 28]             196\n",
      "              ReLU-2                [-1, 1, 28]               0\n",
      "            Linear-3                [-1, 1, 66]           1,914\n",
      "         LeakyReLU-4                [-1, 1, 66]               0\n",
      "           Dropout-5                [-1, 1, 66]               0\n",
      "            Linear-6                [-1, 1, 33]           2,211\n",
      "         LeakyReLU-7                [-1, 1, 33]               0\n",
      "            Linear-8                [-1, 1, 33]           1,122\n",
      "           Sigmoid-9                [-1, 1, 33]               0\n",
      "================================================================\n",
      "Total params: 5,443\n",
      "Trainable params: 5,443\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 21, 30],\n",
       "       [27, 30, 24],\n",
       "       [30,  6, 27],\n",
       "       ...,\n",
       "       [21, 24, 30],\n",
       "       [24, 21, 30],\n",
       "       [24, 30, 26]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test).detach().numpy().argsort(axis=1)[:,:-4:-1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(Y_test.detach().numpy(), axis=2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 -> 6, 2, 8\n",
      "4 -> 6, 8, 4\n",
      "6 -> 8, 10, 6\n",
      "6 SHORT -> 8, 4, 2\n",
      "12 -> 2, 10, 8\n",
      "6 -> 4, 6, 8\n",
      "6 -> 2, 4, 8\n",
      "6 -> 4, 8, 6\n",
      "0 -> 4, 6, 2\n",
      "4 -> 4, 8, 6\n",
      "12 LONG -> 6, 10, 8\n",
      "8 -> 10, 4, 8\n",
      "0 -> 6, 4, 2\n",
      "8 -> 6, 4, 2\n",
      "6 -> 6, 8, 4\n",
      "2 -> 4, 6, 2\n",
      "6 -> 8, 10, 6\n",
      "4 -> 4, 6, 2\n",
      "6 -> 2, 4, 8\n",
      "4 -> 6, 4, 2\n",
      "4 SHORT -> 4, 8, 2\n",
      "4 -> 4, 6, 2\n",
      "0 SHORT -> 4, 6, 2\n",
      "6 -> 6, 8, 4\n",
      "4 -> 2, 8, 6\n",
      "10 -> 2, 4, 8\n",
      "10 -> 8, 2, 4\n",
      "2 -> 6, 2, 8\n",
      "6 -> 2, 4, 8\n",
      "12 -> 6, 4, 8\n",
      "6 -> 4, 6, 2\n",
      "2 LONG -> 2, 8, 4\n",
      "6 -> 2, 4, 8\n",
      "0 SHORT -> 4, 2, 6\n",
      "4 -> 6, 8, 4\n",
      "0 -> 8, 4, 2\n",
      "8 -> 2, 8, 4\n",
      "8 -> 4, 2, 8\n",
      "0 SHORT -> 4, 8, 6\n",
      "6 -> 2, 4, 8\n",
      "8 -> 6, 4, 2\n",
      "18 -> 8, 6, 10\n",
      "6 SHORT -> 4, 8, 2\n",
      "4 -> 4, 6, 8\n",
      "0 -> 8, 4, 10\n",
      "4 -> 6, 4, 2\n",
      "4 -> 2, 4, 10\n",
      "10 -> 8, 4, 2\n",
      "6 -> 2, 8, 4\n",
      "4 SHORT -> 6, 8, 4\n",
      "8 -> 2, 4, 8\n",
      "4 -> 2, 4, 8\n",
      "4 SHORT -> 6, 4, 8\n",
      "8 SHORT -> 4, 8, 10\n",
      "4 -> 4, 8, 2 SHORT\n",
      "10 -> 8, 2, 6\n",
      "8 -> 8, 2, 10\n",
      "2 -> 4, 6, 8\n",
      "12 -> 2, 10, 8\n",
      "6 -> 6, 2, 8\n",
      "12 -> 10, 2, 8\n",
      "4 -> 4, 8, 6\n",
      "2 -> 8, 6, 12\n",
      "00 SHORT -> 8, 4, 2\n",
      "8 SHORT -> 2, 4, 8\n",
      "6 -> 4, 8, 2\n",
      "2 SHORT -> 0, 4, 6\n",
      "2 -> 4, 2, 8\n",
      "10 -> 4, 8, 6 SHORT\n",
      "10 -> 4, 8, 6\n",
      "12 -> 8, 2, 4\n",
      "8 -> 4, 2, 6\n",
      "4 SHORT -> 8, 4, 0\n",
      "10 -> 4, 8, 6\n",
      "10 LONG -> 6, 4, 2\n",
      "6 SHORT -> 4, 6, 2\n",
      "6 -> 4, 12, 8\n",
      "6 -> 8, 4, 2\n",
      "2 -> 6, 4, 2\n",
      "6 -> 8, 4, 2\n",
      "6 LONG -> 6, 4, 2\n",
      "8 -> 6, 4, 2\n",
      "0 -> 6, 8, 10\n",
      "00 SHORT -> 4, 2, 8\n",
      "4 -> 2, 4, 8\n",
      "2 -> 8, 4, 14\n",
      "8 -> 4, 8, 6\n",
      "6 -> 4, 2, 6\n",
      "2 -> 2, 4, 8\n",
      "6 -> 8, 6, 2\n",
      "6 -> 4, 2, 8\n",
      "0 -> 6, 4, 8\n",
      "2 -> 6, 4, 2\n",
      "18 SHORT -> 4, 6, 2\n",
      "2 -> 4, 2, 8\n",
      "2 -> 4, 6, 12\n",
      "0 -> 4, 8, 6\n",
      "0 -> 6, 4, 8\n",
      "8 -> 4, 6, 2\n",
      "6 LONG -> 2, 4, 6\n",
      "4 -> 2, 4, 8\n",
      "0 -> 4, 2, 8\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for true, claims in zip(y, y_pred):\n",
    "    predictions = \", \".join(labels[n] for n in claims[:3])\n",
    "    print(labels[true], \"->\", predictions)\n",
    "    if n > 100:\n",
    "        break\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
