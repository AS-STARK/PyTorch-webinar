{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks with Networks\n",
    "\n",
    "* An image classifier\n",
    "* A regression prediction\n",
    "* Clustering with NNs (note: https://github.com/MarcTLaw/DeepSpectralClusteringToy)\n",
    "* Generative Adversarial Networks (GAN)\n",
    "* Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "\n",
    "**Intermediate Machine Learning with PyTorch**: This last lesson of the Beginning material covered several real world neural networks.  For a deeper dive into some specialize areas, come back for a future webinar session on Intermidiate material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bra_size_chest</th>\n",
       "      <th>bra_size_cup</th>\n",
       "      <th>height</th>\n",
       "      <th>shoe_size</th>\n",
       "      <th>weight</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6 SHORT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  bra_size_chest  bra_size_cup  height  shoe_size  weight   TARGET\n",
       "0  30.0            34.0           5.0    62.0        7.0   128.0  6 SHORT\n",
       "1  20.0            34.0           3.0    64.0        8.0   145.0  6 SHORT\n",
       "2  26.0            32.0           4.0    64.0        8.0   148.0  6 SHORT\n",
       "3  43.0            34.0           5.0    61.0        7.0   145.0  6 SHORT\n",
       "4  63.0            38.0           3.0    63.0        8.0   130.0  6 SHORT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/garments.csv.gz')\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age', 'bra_size_chest', 'bra_size_cup', 'height', 'shoe_size', 'weight']]\n",
    "df_one_hot = pd.get_dummies(df)\n",
    "Y = df_one_hot[[col for col in df_one_hot.columns if col.startswith('TARGET')]]\n",
    "labels = [col.replace('TARGET_', '') for col in Y.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "# The number of input features\n",
    "in_dim = X.shape[1]\n",
    "\n",
    "# The number of \"polynomial features\" of order 2\n",
    "hidden1 = int(in_dim * 2 + (in_dim * (in_dim-1) / 2) + 1)\n",
    "out_dim = Y.shape[1]\n",
    "\n",
    "# The sizes of the \"inference layers\"\n",
    "hidden2 = 2 * out_dim   \n",
    "hidden3 = out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 33, 28, 66, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dim, out_dim, hidden1, hidden2, hidden3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential NN\n",
    "model = torch.nn.Sequential(\n",
    "    # This layer allows \"polynomial features\"\n",
    "    torch.nn.Linear(in_dim, hidden1),\n",
    "    # The activation is treated as a separate layer\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    # This layer is \"inference\"\n",
    "    torch.nn.Linear(hidden1, hidden2),\n",
    "    # Often Leaky ReLU eliminates the \"dead neuron\" danger\n",
    "    torch.nn.LeakyReLU(), \n",
    "    \n",
    "    # A Dropout layer sometimes reduces co-adaptation of neurons\n",
    "    torch.nn.Dropout(p=0.25),\n",
    "\n",
    "    # This layer is \"inference\"\n",
    "    torch.nn.Linear(hidden2, hidden3),\n",
    "    torch.nn.LeakyReLU(), \n",
    "\n",
    "    # A sigmoid activation is used for a binary decision\n",
    "    # Since we use one-hot encoding, we essentially make a \n",
    "    torch.nn.Linear(hidden3, out_dim),  \n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(model, X_train, Y_train, optimizer, batch_size=1000, show_every=250):\n",
    "    for t in range(5000):\n",
    "        # Sample a few training rows\n",
    "        indices = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        X = X_train[indices]\n",
    "        Y = Y_train[indices]\n",
    "        \n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        Y_pred = model(X)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(Y_pred, Y)\n",
    "        if not t % show_every:\n",
    "            print(t, loss)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(18260904., grad_fn=<MseLossBackward>)\n",
      "100 tensor(6267635., grad_fn=<MseLossBackward>)\n",
      "200 tensor(1705114.3750, grad_fn=<MseLossBackward>)\n",
      "300 tensor(1091557., grad_fn=<MseLossBackward>)\n",
      "400 tensor(1014259.4375, grad_fn=<MseLossBackward>)\n",
      "500 tensor(1003724.3125, grad_fn=<MseLossBackward>)\n",
      "600 tensor(987928.3750, grad_fn=<MseLossBackward>)\n",
      "700 tensor(985802.6875, grad_fn=<MseLossBackward>)\n",
      "800 tensor(982526.5000, grad_fn=<MseLossBackward>)\n",
      "900 tensor(980437.9375, grad_fn=<MseLossBackward>)\n",
      "1000 tensor(976926.2500, grad_fn=<MseLossBackward>)\n",
      "1100 tensor(972897.8125, grad_fn=<MseLossBackward>)\n",
      "1200 tensor(969080.6250, grad_fn=<MseLossBackward>)\n",
      "1300 tensor(975465.1250, grad_fn=<MseLossBackward>)\n",
      "1400 tensor(969783.0625, grad_fn=<MseLossBackward>)\n",
      "1500 tensor(969482., grad_fn=<MseLossBackward>)\n",
      "1600 tensor(968283.1250, grad_fn=<MseLossBackward>)\n",
      "1700 tensor(963359.5625, grad_fn=<MseLossBackward>)\n",
      "1800 tensor(965612.5000, grad_fn=<MseLossBackward>)\n",
      "1900 tensor(955097.3125, grad_fn=<MseLossBackward>)\n",
      "2000 tensor(956353.6875, grad_fn=<MseLossBackward>)\n",
      "2100 tensor(953451.5000, grad_fn=<MseLossBackward>)\n",
      "2200 tensor(952226.1875, grad_fn=<MseLossBackward>)\n",
      "2300 tensor(949612.2500, grad_fn=<MseLossBackward>)\n",
      "2400 tensor(949187.9375, grad_fn=<MseLossBackward>)\n",
      "2500 tensor(951468.2500, grad_fn=<MseLossBackward>)\n",
      "2600 tensor(947861.6250, grad_fn=<MseLossBackward>)\n",
      "2700 tensor(942446.7500, grad_fn=<MseLossBackward>)\n",
      "2800 tensor(937869.6250, grad_fn=<MseLossBackward>)\n",
      "2900 tensor(936636.5625, grad_fn=<MseLossBackward>)\n",
      "3000 tensor(937037.2500, grad_fn=<MseLossBackward>)\n",
      "3100 tensor(931396.4375, grad_fn=<MseLossBackward>)\n",
      "3200 tensor(935328.7500, grad_fn=<MseLossBackward>)\n",
      "3300 tensor(933691.4375, grad_fn=<MseLossBackward>)\n",
      "3400 tensor(940957.9375, grad_fn=<MseLossBackward>)\n",
      "3500 tensor(933530.6875, grad_fn=<MseLossBackward>)\n",
      "3600 tensor(936016.8750, grad_fn=<MseLossBackward>)\n",
      "3700 tensor(931722.8125, grad_fn=<MseLossBackward>)\n",
      "3800 tensor(932914.5000, grad_fn=<MseLossBackward>)\n",
      "3900 tensor(930666.8125, grad_fn=<MseLossBackward>)\n",
      "4000 tensor(929975.1250, grad_fn=<MseLossBackward>)\n",
      "4100 tensor(925576.3750, grad_fn=<MseLossBackward>)\n",
      "4200 tensor(926834.3125, grad_fn=<MseLossBackward>)\n",
      "4300 tensor(928365.6250, grad_fn=<MseLossBackward>)\n",
      "4400 tensor(924983.0625, grad_fn=<MseLossBackward>)\n",
      "4500 tensor(923345.9375, grad_fn=<MseLossBackward>)\n",
      "4600 tensor(927039.9375, grad_fn=<MseLossBackward>)\n",
      "4700 tensor(928198.5000, grad_fn=<MseLossBackward>)\n",
      "4800 tensor(921425.5000, grad_fn=<MseLossBackward>)\n",
      "4900 tensor(926847.6875, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Split the original data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "# Convert arrays to tensors\n",
    "X_train = torch.from_numpy(X_train.values).float()\n",
    "Y_train = torch.from_numpy(Y_train.values[:, np.newaxis]).float()\n",
    "X_test = torch.from_numpy(X_test.values).float()\n",
    "Y_test = torch.from_numpy(Y_test.values[:, np.newaxis]).float()\n",
    "\n",
    "## Now run model\n",
    "loss_fn = torch.nn.MSELoss(reduction='elementwise_mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "do_training(model, X_train, Y_train, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 28]             196\n",
      "              ReLU-2                [-1, 1, 28]               0\n",
      "            Linear-3                [-1, 1, 66]           1,914\n",
      "         LeakyReLU-4                [-1, 1, 66]               0\n",
      "           Dropout-5                [-1, 1, 66]               0\n",
      "            Linear-6                [-1, 1, 33]           2,211\n",
      "         LeakyReLU-7                [-1, 1, 33]               0\n",
      "            Linear-8                [-1, 1, 33]           1,122\n",
      "           Sigmoid-9                [-1, 1, 33]               0\n",
      "================================================================\n",
      "Total params: 5,443\n",
      "Trainable params: 5,443\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model(X_train).detach().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(Y_train.detach().numpy(), axis=2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 LONG / 6\n",
      "4 / 6\n",
      "6 SHORT / 4\n",
      "2 / 6\n",
      "10 / 6\n",
      "14 / 6\n",
      "14 / 6\n",
      "10 / 4\n",
      "0 / 4\n",
      "2 / 4\n",
      "2 / 6\n",
      "8 / 4\n",
      "0 / 6\n",
      "12 / 6\n",
      "8 SHORT / 6\n",
      "8 SHORT / 6\n",
      "12 / 4\n",
      "4 / 6\n",
      "6 / 6\n",
      "4 / 4\n",
      "8 / 4\n",
      "6 / 4\n",
      "4 / 6\n",
      "12 / 6\n",
      "4 / 6\n",
      "6 / 6\n",
      "2 LONG / 4\n",
      "10 / 6\n",
      "8 LONG / 6\n",
      "14 / 4\n",
      "00 SHORT / 4\n",
      "4 / 6\n",
      "8 / 6\n",
      "10 / 6\n",
      "00 / 6\n",
      "6 / 6\n",
      "2 / 6\n",
      "6 / 4\n",
      "6 / 6\n",
      "2 / 6\n",
      "4 / 6\n",
      "4 SHORT / 4\n",
      "12 / 6\n",
      "8 SHORT / 4\n",
      "4 / 6\n",
      "0 SHORT / 4\n",
      "0 / 6\n",
      "6 / 6\n",
      "4 / 6\n",
      "16 LONG / 4\n",
      "14 SHORT / 4\n",
      "4 / 6\n",
      "6 / 8\n",
      "6 LONG / 4\n",
      "8 / 4\n",
      "4 / 6\n",
      "2 / 4\n",
      "4 / 6\n",
      "12 LONG / 6\n",
      "0 / 8\n",
      "8 / 6\n",
      "4 SHORT / 6\n",
      "00 SHORT / 6\n",
      "4 / 6\n",
      "10 / 4\n",
      "6 / 4\n",
      "4 / 6\n",
      "8 / 2\n",
      "12 / 4\n",
      "6 / 6\n",
      "0 / 6\n",
      "8 / 6\n",
      "16 LONG / 4\n",
      "2 / 6\n",
      "14 SHORT / 4\n",
      "2 / 6\n",
      "6 / 6\n",
      "4 / 6\n",
      "2 / 4\n",
      "2 SHORT / 6\n",
      "8 / 6\n",
      "6 / 4\n",
      "2 / 4\n",
      "4 / 4\n",
      "4 / 4\n",
      "2 SHORT / 6\n",
      "14 / 6\n",
      "12 / 6\n",
      "12 / 4\n",
      "4 / 6\n",
      "2 / 6\n",
      "12 / 6\n",
      "6 / 6\n",
      "0 SHORT / 6\n",
      "8 / 6\n",
      "4 / 6\n",
      "8 / 6\n",
      "8 / 4\n",
      "6 / 6\n",
      "2 / 4\n",
      "00 / 4\n",
      "2 / 6\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for true, claim in zip(y, y_pred):\n",
    "    print(labels[true], \"/\", labels[claim])\n",
    "    if n > 100:\n",
    "        break\n",
    "    n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
