{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks with Networks\n",
    "\n",
    "* An image classifier\n",
    "* A regression prediction\n",
    "* Clustering with NNs (note: https://github.com/MarcTLaw/DeepSpectralClusteringToy)\n",
    "* Generative Adversarial Networks (GAN)\n",
    "* Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# For demonstration, we can use CPU target if CUDA not available\n",
    "device = torch.device('cpu')\n",
    "# Uncomment this to run on GPU\n",
    "device = torch.device('cuda') \n",
    "\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "\n",
    "**Intermediate Machine Learning with PyTorch**: This last lesson of the Beginning material covered several real world neural networks.  For a deeper dive into some specialize areas, come back for a future webinar session on Intermidiate material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bra_size_chest</th>\n",
       "      <th>bra_size_cup</th>\n",
       "      <th>height</th>\n",
       "      <th>shoe_size</th>\n",
       "      <th>weight</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  bra_size_chest  bra_size_cup  height  shoe_size  weight TARGET\n",
       "0  30.0            34.0           5.0    62.0        7.0   128.0      6\n",
       "1  20.0            34.0           3.0    64.0        8.0   145.0      6\n",
       "2  26.0            32.0           4.0    64.0        8.0   148.0      6\n",
       "3  43.0            34.0           5.0    61.0        7.0   145.0      6\n",
       "4  63.0            38.0           3.0    63.0        8.0   130.0      6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/garments.csv.gz', dtype={'TARGET':str})\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '0', '2', '4', '6', '8', '10', '12', '14', '16', '18']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['age', 'bra_size_chest', 'bra_size_cup', 'height', 'shoe_size', 'weight']]\n",
    "\n",
    "# One-hot encoding\n",
    "df_one_hot = pd.get_dummies(df)\n",
    "Y = df_one_hot[[col for col in df_one_hot.columns if col.startswith('TARGET')]]\n",
    "\n",
    "# Nicer order for columns (sorted by size not lexicographically)\n",
    "Y.columns = [col.replace('TARGET_', '') for col in Y.columns] \n",
    "Y = Y['00 0 2 4 6 8 10 12 14 16 18'.split()]\n",
    "labels = list(Y.columns)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of input features\n",
    "in_dim = X.shape[1]\n",
    "\n",
    "# The number of \"polynomial features\" of order 2\n",
    "hidden1 = int(in_dim * 2 + (in_dim * (in_dim-1) / 2) + 1)\n",
    "out_dim = Y.shape[1]\n",
    "\n",
    "# The sizes of the \"inference layers\"/\n",
    "hidden2 = hidden3 = hidden4 = 2 * out_dim   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 28, 22, 22, 22, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dim, hidden1, hidden2, hidden3, hidden4, out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(model, X_train, Y_train, optimizer, loss_fn, \n",
    "                batch_size=1000, show_every=500):\n",
    "    last_loss \n",
    "    for t in range(50_001):\n",
    "        # Sample a few training rows\n",
    "        indices = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        X = X_train[indices]\n",
    "        Y = Y_train[indices]\n",
    "        \n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        Y_pred = model(X)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(Y_pred, Y)\n",
    "        if not t % show_every:\n",
    "            print(\"Iteration: %d; Loss: %f\" % (t, loss.item()))\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model). This is because by default, gradients are\n",
    "        # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "        # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential NN\n",
    "model = torch.nn.Sequential(\n",
    "    # This layer allows \"polynomial features\"\n",
    "    torch.nn.Linear(in_dim, hidden1),\n",
    "    # The activation is treated as a separate layer\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    # This layer is \"inference\"\n",
    "    torch.nn.Linear(hidden1, hidden2),\n",
    "    # Often Leaky ReLU eliminates the \"dead neuron\" danger\n",
    "    torch.nn.LeakyReLU(), \n",
    "    \n",
    "    # A Dropout layer sometimes reduces co-adaptation of neurons\n",
    "    torch.nn.Dropout(p=0.1),\n",
    "\n",
    "    # This layer is \"inference\"\n",
    "    torch.nn.Linear(hidden2, hidden3),\n",
    "    torch.nn.LeakyReLU(), \n",
    "    torch.nn.Dropout(p=0.1),\n",
    "    \n",
    "    # This layer is \"inference\"\n",
    "    torch.nn.Linear(hidden3, hidden4),\n",
    "    torch.nn.LeakyReLU(), \n",
    "    torch.nn.Dropout(p=0.1),\n",
    "\n",
    "    # A sigmoid activation is used for a binary decision\n",
    "    # Since we use one-hot encoding, we essentially make a \n",
    "    torch.nn.Linear(hidden4, out_dim),  \n",
    "    torch.nn.Sigmoid()\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,264 bytes allocated on GPU\n",
      "16,919,552 bytes allocated on GPU\n"
     ]
    }
   ],
   "source": [
    "# Free up the GPU\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"{torch.cuda.memory_allocated():,} bytes allocated on GPU\")\n",
    "\n",
    "# Split the original data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "\n",
    "# Convert arrays to tensors\n",
    "X_train = torch.from_numpy(X_train.values).float().to(device)\n",
    "X_test  = torch.from_numpy(X_test.values).float().to(device)\n",
    "Y_train = torch.from_numpy(Y_train.values)[:, np.newaxis].float().to(device)\n",
    "Y_test  = torch.from_numpy(Y_test.values)[:, np.newaxis].float().to(device)\n",
    "\n",
    "print(f\"{torch.cuda.memory_allocated():,} bytes allocated on GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 28]             196\n",
      "              ReLU-2                [-1, 1, 28]               0\n",
      "            Linear-3                [-1, 1, 22]             638\n",
      "         LeakyReLU-4                [-1, 1, 22]               0\n",
      "           Dropout-5                [-1, 1, 22]               0\n",
      "            Linear-6                [-1, 1, 22]             506\n",
      "         LeakyReLU-7                [-1, 1, 22]               0\n",
      "           Dropout-8                [-1, 1, 22]               0\n",
      "            Linear-9                [-1, 1, 22]             506\n",
      "        LeakyReLU-10                [-1, 1, 22]               0\n",
      "          Dropout-11                [-1, 1, 22]               0\n",
      "           Linear-12                [-1, 1, 11]             253\n",
      "          Sigmoid-13                [-1, 1, 11]               0\n",
      "================================================================\n",
      "Total params: 2,099\n",
      "Trainable params: 2,099\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, torch.optim.adam.Adam)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr'], optimizer.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; Loss: 0.356154\n",
      "Iteration: 500; Loss: 0.088043\n",
      "Iteration: 1000; Loss: 0.085316\n",
      "Iteration: 1500; Loss: 0.083695\n",
      "Iteration: 2000; Loss: 0.081858\n",
      "Iteration: 2500; Loss: 0.081749\n",
      "Iteration: 3000; Loss: 0.081408\n",
      "Iteration: 3500; Loss: 0.080968\n",
      "Iteration: 4000; Loss: 0.080899\n",
      "Iteration: 4500; Loss: 0.080089\n",
      "Iteration: 5000; Loss: 0.080360\n",
      "Iteration: 5500; Loss: 0.080819\n",
      "Iteration: 6000; Loss: 0.080149\n",
      "Iteration: 6500; Loss: 0.080082\n",
      "Iteration: 7000; Loss: 0.080679\n",
      "Iteration: 7500; Loss: 0.079330\n",
      "Iteration: 8000; Loss: 0.080221\n",
      "Iteration: 8500; Loss: 0.080072\n",
      "Iteration: 9000; Loss: 0.080327\n",
      "Iteration: 9500; Loss: 0.079938\n",
      "Iteration: 10000; Loss: 0.080002\n",
      "Iteration: 10500; Loss: 0.080097\n",
      "Iteration: 11000; Loss: 0.079698\n",
      "Iteration: 11500; Loss: 0.080279\n",
      "Iteration: 12000; Loss: 0.079667\n",
      "Iteration: 12500; Loss: 0.079830\n",
      "Iteration: 13000; Loss: 0.080481\n",
      "Iteration: 13500; Loss: 0.079623\n",
      "Iteration: 14000; Loss: 0.079569\n",
      "Iteration: 14500; Loss: 0.080091\n",
      "Iteration: 15000; Loss: 0.079663\n",
      "Iteration: 15500; Loss: 0.079635\n",
      "Iteration: 16000; Loss: 0.079461\n",
      "Iteration: 16500; Loss: 0.079411\n",
      "Iteration: 17000; Loss: 0.079552\n",
      "Iteration: 17500; Loss: 0.079920\n",
      "Iteration: 18000; Loss: 0.079705\n",
      "Iteration: 18500; Loss: 0.079717\n",
      "Iteration: 19000; Loss: 0.079761\n",
      "Iteration: 19500; Loss: 0.080005\n",
      "Iteration: 20000; Loss: 0.079430\n",
      "Iteration: 20500; Loss: 0.079918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0d8f7e8520ef>\u001b[0m in \u001b[0;36mdo_training\u001b[0;34m(model, X_train, Y_train, optimizer, loss_fn, batch_size, show_every)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Calling the step function on an Optimizer makes an update to its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Now run model\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "do_training(model, X_train, Y_train, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randrange\n",
    "\n",
    "ndx = randrange(len(X_test))\n",
    "probs = model(X_test[ndx])\n",
    "truth = torch.argmax(Y_test[ndx]).item()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(labels, probs.cpu().detach().numpy())\n",
    "plt.bar(truth, 1.1*max(probs.cpu().detach().numpy()), width=.25, color='red')\n",
    "plt.xticks(range(len(labels)), labels, fontsize=8, rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 2],\n",
       "       [4, 3, 2],\n",
       "       [3, 4, 2],\n",
       "       ...,\n",
       "       [3, 4, 2],\n",
       "       [3, 4, 2],\n",
       "       [3, 4, 2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test).cpu().detach().numpy().argsort(axis=1)[:,:-4:-1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(Y_test.cpu().detach().numpy(), axis=2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 -> 6, 4, 2\n",
      "8 -> 6, 4, 2\n",
      "14 -> 4, 6, 2\n",
      "8 -> 4, 6, 8\n",
      "12 -> 4, 6, 8\n",
      "8 -> 4, 6, 2\n",
      "8 -> 6, 4, 2\n",
      "6 -> 4, 6, 2\n",
      "2 -> 4, 6, 2\n",
      "6 -> 6, 4, 8\n",
      "4 -> 4, 6, 2\n",
      "4 -> 4, 6, 8\n",
      "8 -> 4, 6, 2\n",
      "00 -> 4, 6, 2\n",
      "6 -> 4, 6, 8\n",
      "12 -> 4, 6, 2\n",
      "8 -> 4, 6, 8\n",
      "2 -> 4, 6, 8\n",
      "2 -> 4, 6, 8\n",
      "12 -> 4, 6, 8\n",
      "8 -> 4, 6, 2\n",
      "4 -> 4, 6, 8\n",
      "8 -> 4, 6, 2\n",
      "2 -> 4, 6, 2\n",
      "8 -> 6, 4, 2\n",
      "0 -> 4, 6, 2\n",
      "00 -> 4, 6, 2\n",
      "0 -> 4, 6, 2\n",
      "12 -> 4, 6, 2\n",
      "4 -> 6, 4, 2\n",
      "2 -> 4, 6, 2\n",
      "0 -> 4, 6, 2\n",
      "12 -> 4, 6, 2\n",
      "4 -> 4, 6, 2\n",
      "2 -> 4, 6, 2\n",
      "2 -> 4, 6, 2\n",
      "00 -> 4, 6, 2\n",
      "4 -> 4, 6, 8\n",
      "8 -> 4, 6, 2\n",
      "10 -> 4, 6, 2\n",
      "6 -> 6, 4, 2\n",
      "6 -> 4, 6, 2\n",
      "6 -> 6, 4, 8\n",
      "2 -> 6, 4, 2\n",
      "10 -> 6, 4, 2\n",
      "00 -> 6, 4, 8\n",
      "8 -> 4, 6, 2\n",
      "4 -> 4, 6, 2\n",
      "00 -> 6, 4, 8\n",
      "12 -> 4, 6, 2\n",
      "2 -> 4, 6, 8\n",
      "8 -> 4, 6, 2\n",
      "2 -> 6, 4, 8\n",
      "8 -> 4, 6, 2\n",
      "0 -> 4, 6, 2\n",
      "4 -> 6, 4, 2\n",
      "0 -> 4, 6, 2\n",
      "2 -> 6, 4, 8\n",
      "12 -> 4, 6, 2\n",
      "2 -> 4, 6, 8\n",
      "4 -> 4, 6, 2\n",
      "6 -> 4, 6, 2\n",
      "4 -> 6, 4, 2\n",
      "10 -> 4, 6, 2\n",
      "4 -> 6, 4, 2\n",
      "2 -> 4, 6, 8\n",
      "4 -> 4, 6, 2\n",
      "6 -> 6, 4, 2\n",
      "2 -> 6, 4, 2\n",
      "4 -> 4, 6, 2\n",
      "00 -> 4, 6, 2\n",
      "4 -> 4, 6, 2\n",
      "6 -> 4, 6, 2\n",
      "10 -> 4, 6, 8\n",
      "10 -> 6, 4, 8\n",
      "8 -> 6, 4, 8\n",
      "6 -> 4, 6, 8\n",
      "4 -> 6, 4, 8\n",
      "12 -> 4, 6, 2\n",
      "6 -> 6, 4, 2\n",
      "12 -> 6, 4, 8\n",
      "0 -> 4, 6, 2\n",
      "0 -> 6, 4, 2\n",
      "6 -> 4, 6, 2\n",
      "6 -> 4, 6, 2\n",
      "00 -> 4, 6, 2\n",
      "4 -> 4, 6, 2\n",
      "6 -> 4, 6, 2\n",
      "0 -> 4, 6, 2\n",
      "14 -> 4, 6, 8\n",
      "6 -> 4, 6, 2\n",
      "16 -> 4, 6, 2\n",
      "0 -> 4, 6, 2\n",
      "18 -> 4, 6, 8\n",
      "10 -> 4, 6, 8\n",
      "4 -> 6, 4, 8\n",
      "2 -> 4, 6, 2\n",
      "0 -> 4, 6, 8\n",
      "0 -> 6, 4, 8\n",
      "8 -> 4, 6, 2\n",
      "10 -> 6, 4, 8\n",
      "12 -> 4, 6, 2\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for true, claims in zip(y, y_pred):\n",
    "    predictions = \", \".join(labels[n] for n in claims[:3])\n",
    "    print(labels[true], \"->\", predictions)\n",
    "    if n > 100:\n",
    "        break\n",
    "    n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
